What are my career goals?

My career goal is to build a future of Artificial Intelligence that is sustainable and overall a net-positive for our world. I am deeply interested in wanting to progress the betterment of AI technologies both in industry and in academia, but with guidance of people who are also not technologists. I know this goal is very open-ended, but I take that as a form of positivity as I believe I still have many avenues open to where I can progress my career. One thing I am interested in, if I were to attend grad school for a Masters of PhD, is to want to work on Machine Learning Explainability and Interoperability. I think ML Explainability and Interoperability is extremely important for the progression of Human and AI collaboration, as some of our modern Deep Learning models are extremely good at completing certain tasks that are solved with pattern matching that we cannot interpret, the end goal of achieving the task is still good but the ability of human knowledge to progress is stunted because of the black box of Deep Neural Networks. This is critical, because AI is going to continue to make breakthroughs in disciplines like Medicine, the ability to understand these breakthroughs is just as valuable. However, if I choose in the future not to attend university again, I really want to progress my career in building products that are genuinely positive to the world, and I believe my last employment at Genentech/Roche is an example of that. And there are many products or industries that I am sure are truly net positive, and I want to contribute to that growth in the world! My goal in industry would be to not only build the software around ML models, but hopefully also develop those ML models from the ground-up.


What did I do during my time at Genentech?


        After graduating from undergrad at USF in 2021, it took me essentially a full year after university to find a job. I started working at Genentech in June 2022 where I was hired as a Data Engineer within a Clinical Studies AI research group. My role was very different from my Data Engineer colleagues as my role was specifically working under an AI scientist with expertise in developing AI models on Ophthalmology diseases like AMD and Glaucoma. Because of this, I had two supervisors, one was the AI Scientist and the other was the head of Data Engineering, but my AI Scientist supervisor was more my direct supervisor as I was working directly for him. But my Data Engineer supervisor was more of a career guide that really vouched for me and gave me great advice in engineering, but I did not contribute as much to their Data Engineering goals as a team since I was not working directly with them on a regular basis. I would say that my role working in the Ophthalmology AI team was definitely multidisciplinary where I believed I wore many hats other than Data Engineering, like standard Software Engineering, Machine Learning Engineer, and research assistant! I did whatever I needed to assist the team accomplish their research goals whether that meant me engaging with the research itself or building engineering solutions to better help the research team, but it was definitely a learning curve for me to learn how the work expectations of research and engineering teams were different.


        One of the engineering projects I did while at Genentech was my first big project where I had to digitize Visual Field PDF Reports, as this was important in our research of Glaucoma and the progression of Glaucoma through time with patients. This clinical data was shared by Stanford University School of Medicine as a joint-research initiative between both Ophthalmological communities at Genentech and Stanford. To digitize the Visual Field Reports, I used an openly commercially available OCR (optical character recognition) model, called AWS Textract, that outputted the predicted text and bounding boxes of the text of the PDF files. I had to build software on top of the given predictions of AWS Textract to visualize the predictions on top of the pdf, filter and correct patterned mistakes by AWS Textract, and then output CSV files of patient metadata and the 2D 10x10 Decibel Sensitivity graphs of the patients. After testing my tool through manual Data QA, my tool was able to achieve an accuracy of 99.94% on these Visual Field Reports. This tool lead to two published research initiatives, one was my own poster presentation at the American Glaucoma Society annual conference at Austin, TX in 2023 called Digitalization of Humphrey Field Analyzer Reports into CSV. The research done with our partners at Stanford was officially published in TVST ARVO journal, and the paper is called Repeatability of a Virtual Reality Headset Perimeter in Glaucoma and Ocular Hypertensive Patients.


        Another big project I did for my Ophthalmology AI team was completely revamp from scratch a web application that hosted 16 image segmentation models trained on segmenting retinal layers or other retinal deformities in OCT (Optical coherence tomography) images. One of the reasons for the complete revamp, was the issue where only 2 of 16 models were our internal models trained with PyTorch and the other 14 were external models by other Ophthalmology teams within Genentech all using Tensorflow. To come up with a solution I had to learn to containerize the application into three containers; the web application itself, the container that loaded and inferred our internal PyTorch models, and the container that loaded and inferred the external Tensorflow models. I built a REST API using FastAPI that communicated the images and its segmentation results between the containers running the models and the container running the web application to visualize the segmentation results. The API contained AWS S3 keys of a dedicated bucket for the app that would hold user input and segmentation results that would be loaded directly into the app to show the user. I also improved on the original version of the app to take advantage of caching user inputs and segmentation results, and this functionality was easily provided by the web application framework called Streamlit. This made the app very simple to use, and very quick and responsive to implement new features as the containerization via Docker allowed this app to be very scalable. Through my two years at Genentech, this became my greatest software accomplishment as feature requests always came in from its inception to when my contract ended in July 2024. And it is my most prideful accomplishment at Genentech, as it was able to make a tangible difference within the Ophthalmology community throughout the entire company as our AI team was always being reached out to to make improvements, or to integrate their own models to the app that it actually became a home for the Ophthalmology community to share their work with each other. I even remember my AI scientist supervisor mentioning that he was reached out by someone within Genentech that works with primates, and using our app to generate retinal segmentations of their primate!


        Outside of these software tools, I also engaged myself with internal ML research initiatives and projects. One of the research initiatives I took charge of was prototyping Machine Learning models using Decibel Sensitivity graphs of Glaucoma patients to predict future vision loss since we had longitudinal data within our Clinical Study. This allowed me to fully work on an ML project end to end; with building models from scratch, creating datasets of matching inputs and labels, splitting the datasets for training, validation, and testing, hyperparameter tuning, visualizing model training with Weights and Biases, and cross-validation to see which architecture performed the best. With the many unique architectures of Convolutional Neural Networks, and embedding patient metadata like their age and the time difference of the prediction, the conclusion was that the Sensitivity values in the graph and patient metadata is not good enough to predict future vision loss. It turned out that all the models were outputting similar predictions regardless of the input, and through investigation it turned out that the model was just outputting the mean sensitivity graph of all the sensitivity graphs in the training set. Therefore the model was not actually “learning” at all, because it was not able to find patterns between the model’s input and output so the bias was very high! With this conclusion, even though it wasn’t the desired result, guided internal research initiatives as it concluded predicting future vision loss only using the Visual Field Reports was a dead end on the current modeling we were testing. My last big initiative at my time at Genentech was also a Machine Learning initiative, in which I fine tuned public open source Computer Vision models that assisted in correcting past mislabelled image data, and was integrated into a Data QA pipeline to automatically label new injections of clinical study data. The image data were Color Fundus Photography (CFP) images that showed damage to the eyes of Dry AMD of different Field of Views or angles, but the original model was training on Wet AMD, which is another disease that does look different physically in the images. Therefore fine tuning the modes on our Dry AMD data was a Transfer Learning task, and I achieved a 98.1% testing accuracy which was good enough to add it into the Data QA Pipeline. I helped as much as I could at the end of my contract to assist further with the Data QA Pipeline, but not enough to make a great impact.


        I am very grateful for my time at Genentech, but it was stunted at the end of my time by tons of reorganization that eventually split our entire AI research group, and many of my colleagues' contracts were not renewed for this purpose to rebuild. And sadly I was also one of many contract workers chosen to be cut to shuffle resources, which definitely came as a surprise and is still very sobering for me as I am still searching for my next position. However, I really enjoyed my time there, and the ability to work in a research environment after having that taken away for me in university due to Covid has allowed me to understand what it means to work in research. And for me with the intention to further my academic career, has given me better insight of making decisions in my future career, and for that I am eternally thankful.